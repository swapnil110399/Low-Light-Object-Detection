{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import TensorDataset,DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#from kornia.metrics import SSIM\n",
    "import kornia\n",
    "from decomposition import Decomposition\n",
    "from restoration import Restoration\n",
    "from illuminationAdjustment import IlluminationAdjustment,AdjustmentLoss\n",
    "from image_utils import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Set the default GPU (assuming you have at least one GPU)\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "\n",
    "    # Optional: Print the name of the current GPU\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "else:\n",
    "    print('CUDA unavailable')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_images_directory='./../../../../LOLdataset/eval15'\n",
    "test_images_directory='C:/Users/pspra/OneDrive/Desktop/ECE_271_Project/GAN_dataset/test'\n",
    "test_dataset=testData(test_images_directory)\n",
    "global batch_size\n",
    "batch_size = 15\n",
    "\n",
    "test_data_loaders=getDataLoaders(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s',pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom=Decomposition().to(device)\n",
    "rest=Restoration().to(device)\n",
    "adjust=IlluminationAdjustment().to(device)\n",
    "decom.load_state_dict(torch.load('./Saved_models_crop/only_decom_parameters.pth',map_location=device))\n",
    "rest.load_state_dict(torch.load('./Saved_models_crop/only_restoration_parameters.pth',map_location=device))\n",
    "adjust.load_state_dict(torch.load('./Saved_models_crop/only_adjustment_parameters.pth',map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(actual_high, actual_low, r_map, a_map,ref_low,final_img,count):\n",
    "    batch_size = actual_high.shape[0]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10,5))\n",
    "\n",
    "        ax[0].imshow(actual_high[i].detach().numpy().transpose(1, 2, 0))\n",
    "        ax[0].title.set_text('Normal Image')\n",
    "        ax[1].imshow(actual_low[i].detach().numpy().transpose(1, 2, 0))\n",
    "        ax[1].title.set_text('Low Light Image')\n",
    "        ax[2].imshow(final_img[i].detach().numpy().transpose(1, 2, 0))\n",
    "        ax[2].title.set_text('Final Enhanced image')\n",
    "        # ax[2].imshow(ref_low[i].detach().numpy().transpose(1, 2, 0))\n",
    "        # ax[2].title.set_text('Final Enhanced image')\n",
    "        f_name='./Enhanced_images/Image_'+str(count)+'_'+str(i)+'.jpg'\n",
    "        plt.savefig('./Results/Image_'+str(count)+'_'+str(i)+'.jpg')\n",
    "        final_img_np = final_img[i].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        final_img_np = (final_img_np * 255).astype(np.uint8)\n",
    "        Image.fromarray(final_img_np).save(f_name)\n",
    "        #plt.savefig(f_name)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaytight(actual_high, actual_low, r_map, a_map, ref_low, final_img):#,results):\n",
    "    batch_size = actual_high.shape[0]\n",
    "    #rendered_img = results.render()\n",
    "    for i in range(0, batch_size, 2):\n",
    "        if i + 1 < batch_size:\n",
    "\n",
    "            #fig,ax=plt.subplots(1,3,figsize=(10,5))\n",
    "            fig = plt.figure(constrained_layout=False,figsize=(10,5))\n",
    "            subplots = fig.subfigures(1, 2)\n",
    "            ax0 = subplots[0].subplots(1, 2)\n",
    "            ax1 = subplots[1].subplots(1, 2)\n",
    "\n",
    "            ax0[0].imshow(actual_low[i].detach().numpy().transpose(1, 2, 0))\n",
    "            ax0[1].imshow(final_img[i].detach().numpy().transpose(1, 2, 0))\n",
    "            ax0[0].title.set_text('Low Light Image')\n",
    "            ax0[1].title.set_text('Enhanced image')\n",
    "            ax0[0].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "            ax0[1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "            ax1[0].imshow(actual_low[i + 1].detach().numpy().transpose(1, 2, 0))\n",
    "            ax1[1].imshow(final_img[i + 1].detach().numpy().transpose(1, 2, 0))\n",
    "            ax1[0].title.set_text('Low Light Image')\n",
    "            ax1[1].title.set_text('Enhanced image')\n",
    "            ax1[0].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "            ax1[1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "            # ax[0].imshow(actual_low[i].detach().numpy().transpose(1, 2, 0))\n",
    "            # ax[1].imshow(final_img[i].detach().numpy().transpose(1, 2, 0))\n",
    "            # ax[0].title.set_text('Low Light Image')\n",
    "            # ax[1].title.set_text('Enhanced image')\n",
    "            # ax[0].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "            # ax[1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "            # ax[2].imshow(rendered_img[i].detach().numpy().transpose(1, 2, 0))\n",
    "            # ax[2].title.set_text('Detection using YOLO')\n",
    "            # ax[2].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "            \n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom.eval()\n",
    "rest.eval()\n",
    "adjust.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        count=0\n",
    "        for h,l in zip(test_data_loaders['high'],test_data_loaders['low']):\n",
    "                high_img_test,label_high_test=h\n",
    "                low_img_test,label_low_test=l\n",
    "                high_img_test,label_high_test=high_img_test.to(device),label_high_test.to(device)\n",
    "                low_img_test,label_low_test=low_img_test.to(device),label_low_test.to(device)\n",
    "\n",
    "                ref_low,illum_low=decom.forward(low_img_test)\n",
    "                restored_img=rest(ref_low,illum_low)\n",
    "                alpha=3*torch.ones(illum_low.shape[0],1,illum_low.shape[2],illum_low.shape[3]).to(device)\n",
    "                adjustment_map=adjust.forward(illum_low,alpha)\n",
    "                final_img = torch.mul(adjustment_map.expand_as(restored_img), restored_img)              \n",
    "                displayImages(high_img_test,low_img_test,restored_img,adjustment_map,ref_low,final_img,count)\n",
    "                count+=1\n",
    "                #displaytight(high_img_test,low_img_test,restored_img,adjustment_map,ref_low,final_img)#,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
