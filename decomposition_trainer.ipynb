{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import TensorDataset,DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#from kornia.metrics import SSIM\n",
    "import kornia\n",
    "from decomposition import Decomposition,DecomLoss\n",
    "from image_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Set the default GPU \n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "    # Optional: Print the name of the current GPU\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "else:\n",
    "    print('CUDA unavailable')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path to the folder containing the images\n",
    "# Structure is assumed to be:   train_images_directory/high/*.png ; train_images_directory/low/*.png\n",
    "#                               test_images_directory/high/*.png ; test_images_directory/low/*.png\n",
    "\n",
    "train_images_directory='./../../../../LOLdataset/our485'\n",
    "test_images_directory='./../../../../LOLdataset/eval15'\n",
    "\n",
    "train_dataset,test_dataset=preprocessDataset(train_images_directory,test_images_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global batch_size\n",
    "batch_size = 15\n",
    "\n",
    "# Access class names\n",
    "class_data_loaders=getDataLoaders(train_dataset,batch_size)\n",
    "test_data_loaders=getDataLoaders(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying if the data is loaded correctly and iamges are paired appropriately. We user iter to get the first batch of data (10 images)\n",
    "\n",
    "high_img=next(iter(class_data_loaders['high']))\n",
    "low_img=next(iter(class_data_loaders['low']))\n",
    "\n",
    "verifyDataset(high_img,low_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom=Decomposition().to(device)\n",
    "optimizer_decom = torch.optim.Adam(decom.parameters(), lr=0.001,weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_horizontal,sobel_vertical=generateSobelFilters()\n",
    "sobel_horizontal=sobel_horizontal.to(device)\n",
    "sobel_vertical=sobel_vertical.to(device)\n",
    "def displayImages(r_h,r_l,i_h,i_l):\n",
    "    \n",
    "    fig,ax=plt.subplots(2,2,figsize=(8,8))\n",
    "    \n",
    "    ax[0,0].imshow(r_h[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0,0].title.set_text('Reflectance Component for Normal')\n",
    "    ax[0,1].imshow(i_h[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0,1].title.set_text('Illumination Component for Normal')\n",
    "    \n",
    "    \n",
    "    ax[1,0].imshow(r_l[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1,0].title.set_text('Reflectance Component for Low')\n",
    "    ax[1,1].imshow(i_l[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1,1].title.set_text('Illumination Component for Low')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors=[]\n",
    "test_errors=[]\n",
    "max_epochs=31\n",
    "test_at_epochs=list(range(0,max_epochs,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    #print('*************************************************************************************')\n",
    "    decom.train()\n",
    "    epoch_loss = 0.0\n",
    "    for high,low in zip(class_data_loaders['high'],class_data_loaders['low']):\n",
    "\n",
    "        optimizer_decom.zero_grad()\n",
    "        high_img,label_high=high\n",
    "        low_img,label_low=low\n",
    "        high_img,label_high=high_img.to(device),label_high.to(device)\n",
    "        low_img,label_low=low_img.to(device),label_low.to(device)\n",
    "        ref_high,illum_high=decom.forward(high_img)\n",
    "        ref_low,illum_low=decom.forward(low_img)\n",
    "\n",
    "        decom_loss= DecomLoss(ref_low,ref_high,illum_low,illum_high,sobel_horizontal,sobel_vertical,low_img,high_img)\n",
    "        #print(f'Decom loss is {decom_loss}')\n",
    "\n",
    "        epoch_loss+=decom_loss\n",
    "\n",
    "        decom_loss.backward()\n",
    "\n",
    "        optimizer_decom.step()    \n",
    "\n",
    "    final_train_loss=epoch_loss/len(class_data_loaders['high'])\n",
    "\n",
    "    print(f'Epoch {epoch} Train Loss is {final_train_loss}')\n",
    "    train_errors.append(final_train_loss)\n",
    "    displayImages(ref_high.cpu(),ref_low.cpu(),illum_high.cpu(),illum_low.cpu())\n",
    "    if epoch in test_at_epochs and epoch!=0:\n",
    "        decom.eval()\n",
    "        test_loss=0\n",
    "        with torch.no_grad():\n",
    "            for h,l in zip(test_data_loaders['high'],test_data_loaders['low']):\n",
    "                high_img_test,label_high_test=h\n",
    "                low_img_test,label_low_test=l\n",
    "                high_img_test,label_high_test=high_img_test.to(device),label_high_test.to(device)\n",
    "                low_img_test,label_low_test=low_img_test.to(device),label_low_test.to(device)\n",
    "\n",
    "                ref_high_test,illum_high_test=decom.forward(high_img_test)\n",
    "                ref_low_test,illum_low_test=decom.forward(low_img_test)\n",
    "\n",
    "                decom_loss_test= DecomLoss(ref_low_test,ref_high_test,illum_low_test,illum_high_test,sobel_horizontal,sobel_vertical,low_img_test,high_img_test)\n",
    "\n",
    "                test_loss+=decom_loss_test\n",
    "        \n",
    "        final_test_loss=test_loss/len(test_data_loaders['high'])\n",
    "        test_errors.append(final_test_loss)\n",
    "        print(f'Test loss after {epoch} epochs is {final_test_loss} for all test images')\n",
    "        decom.train()\n",
    "        print(f'After {epoch} epochs we have test results as')\n",
    "        displayImages(ref_high_test.cpu(),ref_low_test.cpu(),illum_high_test.cpu(),illum_low_test.cpu())\n",
    "        torch.save(decom,'./Saved_models/only_decomposition_model.pth') # This will save entire model but we need not use the entire model but only need state dict\n",
    "        torch.save(decom.state_dict(), './Saved_models/only_decom_parameters.pth') # This is what needs to be saved which is more portable\n",
    "        torch.save(optimizer_decom.state_dict(), './Saved_models/only_optimizer_decom_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
