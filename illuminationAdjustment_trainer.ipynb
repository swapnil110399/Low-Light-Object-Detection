{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import TensorDataset,DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#from kornia.metrics import SSIM\n",
    "import kornia\n",
    "from decomposition import Decomposition\n",
    "from restoration import Restoration\n",
    "from illuminationAdjustment import IlluminationAdjustment,AdjustmentLoss\n",
    "from image_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Set the default GPU (assuming you have at least one GPU)\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "\n",
    "    # Optional: Print the name of the current GPU\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "else:\n",
    "    print('CUDA unavailable')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path to the folder containing the images\n",
    "# Structure is assumed to be:   train_images_directory/high/*.png ; train_images_directory/low/*.png\n",
    "#                               test_images_directory/high/*.png ; test_images_directory/low/*.png\n",
    "\n",
    "train_images_directory='./../../../../LOLdataset/our485'\n",
    "test_images_directory='./../../../../LOLdataset/eval15'\n",
    "\n",
    "train_dataset,test_dataset=preprocessDataset(train_images_directory,test_images_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global batch_size\n",
    "batch_size = 15\n",
    "\n",
    "# Access class names\n",
    "class_data_loaders=getDataLoaders(train_dataset,batch_size)\n",
    "test_data_loaders=getDataLoaders(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying if the data is loaded correctly and iamges are paired appropriately. We user iter to get the first batch of data (10 images)\n",
    "\n",
    "high_img=next(iter(class_data_loaders['high']))\n",
    "low_img=next(iter(class_data_loaders['low']))\n",
    "\n",
    "verifyDataset(high_img,low_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom=Decomposition().to(device)\n",
    "rest=Restoration().to(device)\n",
    "adjust=IlluminationAdjustment().to(device)\n",
    "optimizer_adjustment = torch.optim.Adam(adjust.parameters(), lr=0.001,weight_decay=0.001)\n",
    "decom.load_state_dict(torch.load('./Saved_models/only_decom_parameters.pth',map_location=device))\n",
    "rest.load_state_dict(torch.load('./Saved_models/only_restoration_parameters.pth',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_horizontal,sobel_vertical=generateSobelFilters()\n",
    "def displayImages(r_h,r_l,i_h,i_l,r_map,a_map):\n",
    "\n",
    "    final_img=torch.mul(a_map.expand_as(r_map),r_map)\n",
    "    \n",
    "    fig,ax=plt.subplots(3,3,figsize=(10,10))\n",
    "    \n",
    "    ax[0,0].imshow(r_h[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0,0].title.set_text('Reflectance Normal')\n",
    "    ax[1,0].imshow(i_h[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1,0].title.set_text('Illumination  Normal')\n",
    "    \n",
    "    ax[0,1].imshow(r_l[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0,1].title.set_text('Reflectance Low')\n",
    "    ax[1,1].imshow(i_l[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1,1].title.set_text('Illumination Low')\n",
    "\n",
    "    ax[0,2].imshow(r_map[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[0,2].title.set_text('Restored Image')\n",
    "    ax[1,2].imshow(a_map[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1,2].title.set_text('Illumination Adjusted Image')\n",
    "    \n",
    "    ax[2,1].imshow(final_img[0].detach().numpy().transpose(1, 2, 0))\n",
    "    ax[2,1].title.set_text('Final Enhanced image')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors=[]\n",
    "test_errors=[]\n",
    "max_epochs=31\n",
    "test_at_epochs=list(range(0,max_epochs,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    #print('*************************************************************************************')\n",
    "    adjust.train()\n",
    "    rest.eval()\n",
    "    decom.eval()\n",
    "    epoch_loss = 0.0\n",
    "    for high,low in zip(class_data_loaders['high'],class_data_loaders['low']):\n",
    "\n",
    "        optimizer_adjustment.zero_grad()\n",
    "        high_img,label_high=high\n",
    "        low_img,label_low=low\n",
    "        high_img,label_high=high_img.to(device),label_high.to(device)\n",
    "        low_img,label_low=low_img.to(device),label_low.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ref_high,illum_high=decom.forward(high_img)\n",
    "            ref_low,illum_low=decom.forward(low_img)\n",
    "        \n",
    "        restoration_map=rest.forward(ref_low,illum_low)\n",
    "\n",
    "        alpha=5*torch.ones(illum_low.shape[0],1,illum_low.shape[2],illum_low.shape[3]).to(device)\n",
    "        adjustment_map=adjust.forward(illum_low,alpha)\n",
    "\n",
    "        adjustment_loss=AdjustmentLoss(adjustment_map,illum_high,sobel_horizontal,sobel_vertical)\n",
    "\n",
    "        epoch_loss+=adjustment_loss\n",
    "\n",
    "        adjustment_loss.backward()\n",
    "\n",
    "        optimizer_adjustment.step()  \n",
    "\n",
    "    final_train_loss=epoch_loss/len(class_data_loaders['high'])\n",
    "\n",
    "    print(f'Epoch {epoch} Train Loss is {final_train_loss}')\n",
    "    train_errors.append(final_train_loss)\n",
    "    #displayImages(ref_high.cpu(),ref_low.cpu(),illum_high.cpu(),illum_low.cpu(),restoration_map.cpu(),adjustment_map.cpu())\n",
    "    if epoch in test_at_epochs and epoch!=0:\n",
    "        rest.eval()\n",
    "        test_loss=0\n",
    "        with torch.no_grad():\n",
    "            #print('Inside test')\n",
    "            for h,l in zip(test_data_loaders['high'],test_data_loaders['low']):\n",
    "                high_img_test,label_high_test=h\n",
    "                low_img_test,label_low_test=l\n",
    "                high_img_test,label_high_test=high_img_test.to(device),label_high_test.to(device)\n",
    "                low_img_test,label_low_test=low_img_test.to(device),label_low_test.to(device)\n",
    "\n",
    "                ref_high_test,illum_high_test=decom.forward(high_img_test)\n",
    "                ref_low_test,illum_low_test=decom.forward(low_img_test)\n",
    "\n",
    "                restoration_map_test=rest.forward(ref_low_test,illum_low_test)\n",
    "                alpha_test=5*torch.ones(illum_low_test.shape[0],1,illum_low_test.shape[2],illum_low_test.shape[3]).to(device)\n",
    "                adjustment_map_test=adjust.forward(illum_low_test,alpha_test)\n",
    "                adjustment_loss_test=AdjustmentLoss(adjustment_map_test,illum_high_test,sobel_horizontal,sobel_vertical)\n",
    "\n",
    "                test_loss+=adjustment_loss_test\n",
    "        \n",
    "        final_test_loss=test_loss/len(test_data_loaders['high'])\n",
    "        test_errors.append(final_test_loss)\n",
    "        print(f'Test loss after {epoch} epochs is {final_test_loss} for all test images')\n",
    "        rest.train()\n",
    "        print(f'After {epoch} epochs we have test results as')\n",
    "        displayImages(ref_high_test.cpu(),ref_low_test.cpu(),illum_high_test.cpu(),illum_low_test.cpu(),restoration_map_test.cpu(),adjustment_map_test.cpu())\n",
    "        torch.save(adjust,'./Saved_models/only_adjustment_model.pth') # This will save entire model but we need not use the entire model but only need state dict\n",
    "        torch.save(adjust.state_dict(), './Saved_models/only_adjustment_parameters.pth') # This is what needs to be saved which is more portable\n",
    "        torch.save(optimizer_adjustment.state_dict(), './Saved_models/only_optimizer_adjustment_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
